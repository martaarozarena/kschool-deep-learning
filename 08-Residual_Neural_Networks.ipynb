{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Lab - Redes Convolucionales.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7GSHz_gCcK4",
        "colab_type": "text"
      },
      "source": [
        "# ResNets\n",
        "\n",
        "Hacemos una configuración de una red neuronal residual como la que mos visto en las transparencias de clase, y vemos que los resultados son mejores que si utilizamos este tipo de arquitectura sin los atajos entre capas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOyQpRREqjhg",
        "colab_type": "text"
      },
      "source": [
        "Hacemos la preparación de datos de MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQG0giwvCuqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# Dimensiones de entrada de la imagen\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# Los datos de training, reordenados y separados en train y test\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train_images = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test_images = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlrMdeA3qsIf",
        "colab_type": "text"
      },
      "source": [
        "Importamos los diferentes tipos de capas. Las novedades aquí son dos:\n",
        "\n",
        "- Utilizamos una nueva capa, `add`, que nos permite hacer la adición de la salida de dos capas previas.\n",
        "- Utilizamos otra API de definición de redes neuronales de Keras, el **Functional API**.\n",
        "\n",
        "Este API nos permite expresar una capa como una función que se aplica sobre una capa previa, y junto con la nueva capa `add` es la que permite configurar una arquitectura residual como se ve en el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_06Bt_d_p4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, add, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "num_classes = 10\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "conv1_1 = Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu', padding='same')(inputs)\n",
        "conv1_2 = Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu', padding='same')(conv1_1)\n",
        "conv1_3 = Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu', padding='same')(conv1_2)\n",
        "skip1 = add([conv1_1, conv1_3])\n",
        "conv1_4 = Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu', padding='same')(skip1)\n",
        "maxpool1 = MaxPooling2D(pool_size=(2, 2))(conv1_4)\n",
        "conv2_1 = Conv2D(32, (3, 3), activation='relu', padding='same')(maxpool1)\n",
        "conv2_2 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv2_1)\n",
        "skip1 = add([maxpool1, conv2_2])\n",
        "conv2_3 = Conv2D(32, (3, 3), activation='relu', padding='same')(skip1)\n",
        "maxpool2 = MaxPooling2D(pool_size=(2, 2))(conv2_3)\n",
        "flat = Flatten()(maxpool2)\n",
        "dense = Dense(64, activation='relu')(flat)\n",
        "predictions = Dense(num_classes, activation='softmax')(dense)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GylE_Flg_p4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPWthjAjFYYA",
        "colab_type": "text"
      },
      "source": [
        "Compilamos y entrenamos la red con los datos de MNIST ya correctamente preprocesados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR5zF94Z_p4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "cnn_w_res = model.fit(X_train_images, y_train,\n",
        "                       batch_size=batch_size, epochs=epochs, verbose=1, validation_split=.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fI1qJgnrkG8",
        "colab_type": "text"
      },
      "source": [
        "Probamos con una arqutiectura distinta, en la que añadimos sólo un atajo en vez de los dos que teníamos previamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5zxK9kM_p4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten\n",
        "from keras.models import Model\n",
        "\n",
        "num_classes = 10\n",
        "inputs = Input(shape=(28, 28, 1))\n",
        "conv1_1 = Conv2D(32, (3, 3), activation='relu',\n",
        "                 padding='same')(inputs)\n",
        "conv1_2 = Conv2D(32, (3, 3), activation='relu',\n",
        "                 padding='same')(conv1_1)\n",
        "maxpool1 = MaxPooling2D(pool_size=(2, 2))(conv1_2)\n",
        "conv2_1 = Conv2D(32, (3, 3), activation='relu',\n",
        "                 padding='same')(maxpool1)\n",
        "conv2_2 = Conv2D(32, (3, 3), activation='relu',\n",
        "                 padding='same')(conv2_1)\n",
        "skip2 = add([maxpool1, conv2_2])\n",
        "maxpool2 = MaxPooling2D(pool_size=(2, 2))(skip2)\n",
        "flat = Flatten()(maxpool2)\n",
        "dense = Dense(64, activation='relu')(flat)\n",
        "predictions = Dense(num_classes, activation='softmax')(dense)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teTC-8fT_p4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfgQs08F_p4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "cnn_w_res = model.fit(X_train_images, y_train,\n",
        "                       batch_size=128, epochs=10, verbose=1, validation_split=.1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}