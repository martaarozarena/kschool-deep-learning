{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "redes-convolucionales.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2mnc-Lr97qD",
        "colab_type": "text"
      },
      "source": [
        "# Introducción a Redes Convolucionales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E64FX1WjibfU",
        "colab_type": "text"
      },
      "source": [
        "## Convoluciones\n",
        "\n",
        "Realizamos un análisis intuitivo del efecto de las convoluciones aplicando filtros sobre una imagen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r5-YYCZ71HH",
        "colab_type": "text"
      },
      "source": [
        "Importamos algunos módulos y hacemos configuraciones para los gráficos del cuaderno:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMmFdo3e97qE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.ndimage import convolve #Usamos la clase convolve para implementar una convolución\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "plt.rcParams[\"savefig.dpi\"] = 300\n",
        "plt.rcParams[\"savefig.bbox\"] = \"tight\"\n",
        "plt.rcParams[\"figure.figsize\"] = (16,9)\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqUYcw0qizbk",
        "colab_type": "text"
      },
      "source": [
        "También preparamos una función para visualizar mejor los gráficos de pérdida y precisión que utilizaremos luego:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYCLPoFCiyKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(logger):\n",
        "    df = pd.DataFrame(logger.history)\n",
        "    df[['accuracy', 'val_accuracy']].plot()\n",
        "    plt.ylabel(\"precisión\")\n",
        "    df[['loss', 'val_loss']].plot(linestyle='--', ax=plt.twinx())\n",
        "    plt.ylabel(\"pérdida\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kozvgsCYhnZI",
        "colab_type": "text"
      },
      "source": [
        "Vamos a generar los datos para hacer un difuminado Gaussiano:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8-i-uym7j1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rng = np.random.RandomState(2)\n",
        "signal = np.cumsum(rng.normal(size=200))\n",
        "plt.plot(signal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLBaChbTiePb",
        "colab_type": "text"
      },
      "source": [
        "Ahora generamos la función filtro gausiano y la mostramos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NG14YBh97qH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gaussian_filter = np.exp(-np.linspace(-2, 2, 15) ** 2)\n",
        "gaussian_filter /= gaussian_filter.sum()\n",
        "plt.plot(gaussian_filter)\n",
        "gaussian_filter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmC8flZr8dQx",
        "colab_type": "text"
      },
      "source": [
        "Aplicamos la convolución (composición) de las dos funciones llamando a la clase `convolve`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVbSArgW97qJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(signal)\n",
        "plt.plot(convolve(signal, gaussian_filter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WvpS3kb_N5P",
        "colab_type": "text"
      },
      "source": [
        "Descargamos una imagen para mostrar cuál es el efecto de un filtro gaussiano sobre una imagen:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZymIkdxo7pG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -o Caballero.jpg \"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/El_caballero_de_la_mano_en_el_pecho.jpg/600px-El_caballero_de_la_mano_en_el_pecho.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPzIgTem_glb",
        "colab_type": "text"
      },
      "source": [
        "Una vez que la imagen está descargada en el sistema de ficheros local, la importamos y la mostramos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrdKqE_u97qL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "image = imageio.imread('Caballero.jpg')\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3u0Jo6W_qaY",
        "colab_type": "text"
      },
      "source": [
        "Usamos el filtro gaussiano unidimensional que creamos más arriba para crear un filtro gaussiano bidimensional y mostramos el aspecto que tiene (esperamos una función discretizada, ya que la definimos así más arriba):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX9aob7g97qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gaussian_2d = gaussian_filter * gaussian_filter[:, np.newaxis]\n",
        "plt.matshow(gaussian_2d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me_p6mBq_64p",
        "colab_type": "text"
      },
      "source": [
        "Ahora hacemos la convolución del filtro sobre la imagen que hemos cargado, para apreciar el efecto que tiene, que debería ser un difuminado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKfwt-du97qP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = convolve(image, gaussian_2d[:, :, np.newaxis])\n",
        "plt.imshow(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA9tQzobAMv4",
        "colab_type": "text"
      },
      "source": [
        "Vamos a transformar la imagen a escala de grises. `image` es un array numpy, para hacer la escala de grises computamos la media entre los tres canales de color de la imagen, que están expresados en la tercera dimensión (el eje 2 del array):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NG6Y_D-AIzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gray_image = image.mean(axis=2)\n",
        "plt.imshow(gray_image, cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHx2GBl7CdhS",
        "colab_type": "text"
      },
      "source": [
        "Componemos ahora un filtro similar al Sobel, para ellos componemos la función que expresa el fitro gaussiano con una matriz [-1,1]:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jvL6EDl97qV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gradient_2d = convolve(gaussian_2d, [[-1, 1]])\n",
        "plt.imshow(gradient_2d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmqE8LWzCu5y",
        "colab_type": "text"
      },
      "source": [
        "Aplicamos este filtro, que lo que va a hacer es resaltar el gradiente en la dirección del eje x de la imagen, mostrando así más intensidad en líneas verticales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arIsxoj_97qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edges = convolve(gray_image, gradient_2d)\n",
        "plt.imshow(edges, cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4dIg16r97qc",
        "colab_type": "text"
      },
      "source": [
        "## CNNs con Keras\n",
        "\n",
        "Vamos a ver cómo se configuran redes convolucionales (CNNs, de *Convolutional Neural Networks*) con Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEWq2ODLkYkD",
        "colab_type": "text"
      },
      "source": [
        "Empezamos con la preparación de datos. Lo primero es el preprocesado de los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsoHECdgDCbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist     # MNIST dataset incluido en Keras\n",
        "from keras.models import Sequential  # Tipo de modelo a utilizar\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten # Tipos de capas que usaremos en nuestro modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFrKK4VFD-Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Los datos MNIST están repartidas entre 60000 imágenes de 28 x 28 píxeles\n",
        "# y 10000 imágenes de 28 x 28 píxeles\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# Separamos los datos en train y test\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape, {y_train.shape}\")\n",
        "print(f\"X_test shape, {X_test.shape}\")\n",
        "print(f\"y_test shape, {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7ycqXW1EfAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pasamos de enteros a números en punto flontate de 32 bits\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalizamos cada valor de cada pixel para cada vector de entrada\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61Rj4oUDZnnm",
        "colab_type": "text"
      },
      "source": [
        "Hacemos un *one hot encoding* de las las etiquetas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObyYzGN1E5et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FlDNtXapgdh",
        "colab_type": "text"
      },
      "source": [
        "Configuramos algunos de los hiperparámetros de la red:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYIFHPdX97qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM1zx2lZplBl",
        "colab_type": "text"
      },
      "source": [
        "Modificamos las dimensiones de las muestras para que sean 4D, tal y como esperan las capas convolucionales en la entrada en Keras. La cuarta dimensión es el canal correspondiente a la imagen en blanco y negro (si fuesen imágenes en color, tendríamos tres canales):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izh9CF2LZJiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape, {X_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fnmeoLAZu8W",
        "colab_type": "text"
      },
      "source": [
        "Configuramos una red neuronal. Es una red pequeña porque no queremos gastar mucho tiempo en el entrenamiento. Vamos a utilizar un modelo secuencia, como hicimos con las MLPs que configuramos con Keras anteriormente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHAUBpQaaJwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKw0bQvyaaq3",
        "colab_type": "text"
      },
      "source": [
        "La capa `Conv2D` acepta varios parámetros. El primero, el número 32 es el número de feature maps que vamos a generar, y el siguiente es el tamaño del kernel (filtro). Así pues, esta primera capa va a aprender 32 kernels de tamaño 3x3.\n",
        "\n",
        "La dimensión de entrada es la que configuramos antes, 28x28x1:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPYOhx8MaYok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyAicQPLbNg4",
        "colab_type": "text"
      },
      "source": [
        "La salida de esta capa tendrá una dimensión de 26x26x32, porque estamos generando 32 convoluciones con kernels de 3x3, que está haciendo una convolución válida. Como el filtro es de 3x3, significa que estamos perdiendo un pixel por cada lado en la matrix inicial de 28x28 que es cada imagen de entrada (la fórmula es que para filtros impares, siempre perdemos un número de pixels = anchura del filtro -1 = 3 - 1 = 2 píxels que perdemos).\n",
        "\n",
        "Hacemos un max pooling con un tamaño de 2x2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmunQNuaaaBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KW8o6SpdEi9",
        "colab_type": "text"
      },
      "source": [
        "Al hacer el max pooling 2x2, la resolución se reduce a la mitad, y de ahí que tengamos 13x13.\n",
        "\n",
        "Añadimos una convolución y un max pooling adicional:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLHmp3KddDcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "cnn.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAWeBR93dYWf",
        "colab_type": "text"
      },
      "source": [
        "Añadimos una capa de flatten, que va a convertir básicamente las 32 matrices bidimensionales que vamos arrastrando en un gran vector que podrá ser la entrada para una capa densa, sobre la que finalmente aplicaremos una activación softmax para que nos de las clases que estamos buscando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waP9Gv2cdXXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(64, activation='relu'))\n",
        "cnn.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHhMo8MrdvQK",
        "colab_type": "text"
      },
      "source": [
        "Si pedimos un resumen de la red, podemos analizar las dimensiones de cada capa y ver que todo tiene sentido:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZDq6_0B97qg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPF-M_tgd4o8",
        "colab_type": "text"
      },
      "source": [
        "Lo interesante de ver aquí es que el número de parámetros entrenables que tenemos en una red convolucional es mucho menor que el número que obteníamos en una red densa convencional como con la que estuvimos trabajando previamente cuando introdujimos Keras.\n",
        "\n",
        "En las primeras capas convolucionales tenemos muy pocos parámetros comparado con el número de parámetros que tenemos en una capa densa.\n",
        "\n",
        "Sin embargo, habitualmente en las CNNs el tamaño de las activaciones es más grande que en las redes convencionales (y, como hemos visto, el número de pesos es más pequeño).\n",
        "\n",
        "Otra cosas interesante es que la segunda capa convolucional tiene muchos más parámetros. Esto es debido a que cada 32 filtros de 3x3 tienen que aplicarse a las 32 imágenes de salida de la capa previa que son resultado a su vez de la aplicación de 32 kernels de 3x3. Así pues, $32(32\\cdot(3\\cdot3)) +32 = 9248$, que coincide con el número de parámetros que deberíamos ver en esa capa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVBWAlyjgnBH",
        "colab_type": "text"
      },
      "source": [
        "Compilamos y entrenamos, utilzando como optimizador `adam`, y usando 20 épocas y reservando un 10% de los datos para validación "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY52g5zL97qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])\n",
        "history_cnn = cnn.fit(X_train_images, y_train,\n",
        "                      batch_size=128, epochs=20, verbose=1, validation_split=.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHxWh1GThE1D",
        "colab_type": "text"
      },
      "source": [
        "El modelo está entrenado, que quiere decir que tiene todos los filtros y los pesos aprendidos. Si queremos utilizarlo cuando cerremos el entorno de ejecución del cuaderno sin tener que volver a entrenar, podemos guardarlo invocando el método `save` de nuestro modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktS4p0v-pMqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.save('mymodel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Q2RvNp97qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_history(history_cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdBt8zSNg9ml",
        "colab_type": "text"
      },
      "source": [
        "Si evaluamos el modelo, vemos que la precisión de test es mejor que lo que obtuvimos antes con una red convencional, pese a que tiene menos parámetros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maQmyky897qm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.evaluate(X_test_images, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlEZm1Wl97qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(history_cnn.history)\n",
        "df[['accuracy', 'val_accuracy']].plot()\n",
        "plt.ylabel(\"precisión\")\n",
        "plt.ylim(.9, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeZcGZmGSZGo",
        "colab_type": "text"
      },
      "source": [
        "Vamos a construir una red algo más pequeña para visualizar los filtros y los resultados de aplicar la convolución (lo que serían nuestros feature maps):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8XwDSon97rH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_small = Sequential()\n",
        "cnn_small.add(Conv2D(8, kernel_size=(3, 3),\n",
        "              activation='relu',\n",
        "              input_shape=input_shape))\n",
        "cnn_small.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_small.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "cnn_small.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_small.add(Flatten())\n",
        "cnn_small.add(Dense(64, activation='relu'))\n",
        "cnn_small.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqcMMuZP97rJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_small.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV5sffxA97rK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_small.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])\n",
        "history_cnn_small = cnn_small.fit(X_train_images, y_train,\n",
        "                      batch_size=128, epochs=10, verbose=1, validation_split=.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZz_ZAoFTDfO",
        "colab_type": "text"
      },
      "source": [
        "Veamos ahora cuáles son las dimensiones que estamos esperando de los diferentes filtros en las dos capas convolucionales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsMWfw4297rN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights, biases = cnn_small.layers[0].get_weights()\n",
        "weights2, biases2 = cnn_small.layers[2].get_weights()\n",
        "print(weights.shape)\n",
        "print(weights2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eUIEJNiN_Gf",
        "colab_type": "text"
      },
      "source": [
        "En la primera capa, tenemos sobre un canal de entrada filtros de 3x3 que nos dan ocho canales de salida, y en la segunda tenemos ocho canales de entrada con filtros de 3x3 que nos dan también ocho canales de salida.\n",
        "\n",
        "Vamos a visualizar los filtros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIJdGSAn97rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(9, 8, figsize=(10, 8), subplot_kw={'xticks': (), 'yticks': ()})\n",
        "mi, ma = weights.min(), weights.max()\n",
        "for ax, weight in zip(axes[0], weights.T):\n",
        "    ax.imshow(weight[0, :, :].T, vmin=mi, vmax=ma)\n",
        "axes[0, 0].set_ylabel(\"layer1\")\n",
        "mi, ma = weights2.min(), weights2.max()\n",
        "for i in range(1, 9):\n",
        "    axes[i, 0].set_ylabel(\"layer3\")\n",
        "for ax, weight in zip(axes[1:].ravel(), weights2.reshape(3, 3, -1).T):\n",
        "    ax.imshow(weight[:, :].T, vmin=mi, vmax=ma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCPkN8frOcGs",
        "colab_type": "text"
      },
      "source": [
        "Tenemos 1 input channel para la primera capa convolucional con filtros de 3x3, y 8 feature maps de salida.\n",
        "\n",
        "Tomando la primera fila, por columnas tenemos los filtros para cada uno de los feature maps se que van a generar.\n",
        "\n",
        "Para la segunda capa convolucional, tenemos 8 canales de entrada y 8 canales de salida. Como funciona es que la segunda fila de filtros en la matriz se aplican a los resultados de los filtros de la primera fila, y se suman para darnos un feature map. Lo mismo con la tercera fila para dar otro feature map y así hasta la novena fila (8 filas correspondientes a la segunda capa), que generan en total 8 feature maps.\n",
        "\n",
        "De esta manera es como se ve que hay más parámetros en la segunda capa convolucional, porque ahora todos los filtros tienen que procesar todos los feature maps generados en la primera capa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3JD-tgU97rQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "get_1rd_layer_output = K.function([cnn_small.layers[0].input],\n",
        "                                  [cnn_small.layers[0].output])\n",
        "get_3rd_layer_output = K.function([cnn_small.layers[0].input],\n",
        "                                  [cnn_small.layers[2].output])\n",
        "\n",
        "layer1_output = get_1rd_layer_output([X_train_images[:5]])[0]\n",
        "layer3_output = get_3rd_layer_output([X_train_images[:5]])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuZw6QWH97rS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer1_output.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zriUTkuV97rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer3_output.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdHbzHKLPtpG",
        "colab_type": "text"
      },
      "source": [
        "Veamos ahora las activaciones de esta red con ocho feature maps y filtros de 3x3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e88z_iD897rU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights, biases = cnn.layers[0].get_weights()\n",
        "n_images = layer1_output.shape[0]\n",
        "n_filters = layer1_output.shape[3]\n",
        "fig, axes = plt.subplots(n_images * 2, n_filters + 1, figsize=(10, 8), subplot_kw={'xticks': (), 'yticks': ()})\n",
        "for i in range(layer1_output.shape[0]):\n",
        "    # for reach input image (= 2 rows)\n",
        "    axes[2 * i, 0].imshow(X_train_images[i, :, :, 0], cmap=\"gray_r\")\n",
        "    axes[2 * i + 1, 0].set_visible(False)\n",
        "    axes[2 * i, 1].set_ylabel(\"layer1\")\n",
        "    axes[2 * i + 1, 1].set_ylabel(\"layer3\")\n",
        "    for j in range(layer1_output.shape[3]):\n",
        "        # for each feature map (same number in layer 1 and 3)\n",
        "        axes[2 * i, j + 1].imshow(layer1_output[i, :, :, j], cmap='gray_r')\n",
        "        axes[2 * i + 1, j + 1].imshow(layer3_output[i, :, :, j], cmap='gray_r')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E2mLm9-P6u2",
        "colab_type": "text"
      },
      "source": [
        "En la primera fila, vemos los feature maps generados a partir de la imagen de la izquierda, que son los resultados una vez aplicados los ocho filtros aprendidos, de dimensiones 26x26. \n",
        "\n",
        "En la segunda fila se ve el resultado de la segunda capa convolucional, 8 feature maps de 11x11 obtenidos como hemos descrito antes. Estas son las activaciones en la segunda capa convolucional, después de la cual se aplican las capas densas.\n",
        "\n",
        "Por ejemplo, puede observarse en la fila correspondiente al número 1 cómo el filtro está claramente priorizando el reconocimiento de una línea vertical ligeramente inclinada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvcfmi9joeko",
        "colab_type": "text"
      },
      "source": [
        "# Batch Normalization\n",
        "\n",
        "Probamos el efecto de Batch Normalization en la red convolucional en este cuaderno que hemos configurado en este cuaderno, y analizamos la mejora de rendimiento que una red convolucional introduce."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFBoB_hqog1y",
        "colab_type": "text"
      },
      "source": [
        "Añadimos un tipo de capa más, `BatchNormalization`, configuramos nuestra red neuronal de una manera muy parecida a cómo hemos hecho antes, pero con capas de Batch Normalization después de las activaciones de las convoluciones:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ6_BTIsom1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import BatchNormalization, Activation\n",
        "\n",
        "cnn_small_bn = Sequential()\n",
        "cnn_small_bn.add(Conv2D(8, kernel_size=(3, 3),\n",
        "                 input_shape=input_shape))\n",
        "cnn_small_bn.add(Activation(\"relu\"))\n",
        "cnn_small_bn.add(BatchNormalization())\n",
        "cnn_small_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_small_bn.add(Conv2D(8, (3, 3)))\n",
        "cnn_small_bn.add(Activation(\"relu\"))\n",
        "cnn_small_bn.add(BatchNormalization())\n",
        "cnn_small_bn.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_small_bn.add(Flatten())\n",
        "cnn_small_bn.add(Dense(64, activation='relu'))\n",
        "cnn_small_bn.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djB9NxlYopZV",
        "colab_type": "text"
      },
      "source": [
        "Revisamos la arquitectura de la red que acabamos de configurar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgtOMv3wo4Yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF-t-0-Wo6o2",
        "colab_type": "text"
      },
      "source": [
        "Escribir el gradiente del minibatch a mano es muy complicado. Sin embargo, todos los frameworks de Deep Learning incorporan *AutoDiff*, que computa los gradientes por nosotros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5rY6fJNpBg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_small_bn.compile(\"adam\", \"categorical_crossentropy\", metrics=['accuracy'])\n",
        "history_cnn_small_bn = cnn_small_bn.fit(X_train_images, y_train,\n",
        "                                        batch_size=128, epochs=10, verbose=1, validation_split=.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MHhdLZOpFVm",
        "colab_type": "text"
      },
      "source": [
        "Aquí tenemos una comparación entre la precisión en training y validación entre una red convolucional pequeña con y sin batch normalization, y se puede ver que los resultados son mejores cuando incorporamos esta técnica:"
      ]
    }
  ]
}