{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo_breastcancer_neural_network.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5fnZVw6Sl8D",
        "colab_type": "text"
      },
      "source": [
        "# Ejemplo de DNNs con Boston Breast Cancer Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDJcK1XNW3Y_",
        "colab_type": "text"
      },
      "source": [
        "## Carga y procesado de los datos\n",
        "\n",
        "Primero, cargamos el dataset de un CSV disponible en Internet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yhlx2ExRdlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/autonomio/datasets/master/autonomio-datasets/breast_cancer.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtVDcBs0S2pN",
        "colab_type": "text"
      },
      "source": [
        "Comprobamos que nuestro fichero CSV está en el sistema de ficheros local de la máquina virtual en la que se está ejecutando Google Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjAkyzSyCxDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rXxK7TkTCn7",
        "colab_type": "text"
      },
      "source": [
        "Ahora, importamos diferentes librerías necesarias para poder procesar los datos, e importamos el CSV en un dataframe de Pandas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsluPna2Cypl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv('breast_cancer.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oVzemZeTRZI",
        "colab_type": "text"
      },
      "source": [
        "Echamos un vistazo al dataset, que ya conocemos bien de las clases de Supervised Learning con Python y Scikit-Learn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNMlD8egDEl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9ugPr06TdXC",
        "colab_type": "text"
      },
      "source": [
        "Ahora separamos las variables dependientes e independientes, nuestras muestras de las etiquetas de clasificación del dataset. Nótese qu extamos excluyendo la última columna de las muestras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkRaEx4FDSoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset.iloc[:, 2:32].values\n",
        "y = dataset.iloc[:, 1].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGfKUSMBTzvx",
        "colab_type": "text"
      },
      "source": [
        "Comprobamos las dimensiones de nuestra matriz de entradas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy_XHjajzQD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W-y1YH2UEDF",
        "colab_type": "text"
      },
      "source": [
        "Ahora realizamos la codificación de datos de clasificación (la *M* y la *B* de las categorías de cancer) en valores binarios con los que podamos trabajar. Para ello, usamos la clase incluída en Scikit-Learn, `LabelEncoder`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOC2Y4_2FdKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "\n",
        "y = labelencoder.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY-v3pKPUeGB",
        "colab_type": "text"
      },
      "source": [
        "Ya que sólo estamos trabajando con dos clases para la predicción, no es necesario realizar un *Hot Encoding* de las etiquetas.\n",
        "\n",
        "Comprobamos las dimensiones del vector de etiquetas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGEasn5XaGrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHF3GBA_UsZ_",
        "colab_type": "text"
      },
      "source": [
        "Ahora, realizamos el particionado de los datos de entrada en conjuntos de entrenamiento y test. Para ello usamos también una clase de Scikit-Learn, en este caso `train_test_split`, con una proporción 80/20 entre los datos de entrenamiento y los datos de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-MZKcZ3LFhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrspAFpLWSvj",
        "colab_type": "text"
      },
      "source": [
        "Una vez tenemos preparados los conjuntos de datos, hacemos también un escalado de las características para mejorar el comportamiento del entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aePbHmfLKJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dK3hmixALohZ",
        "colab_type": "text"
      },
      "source": [
        "## Entrenamiento de la red neuronal\n",
        "\n",
        "Importamos los módulos de Keras necesarios para poder definir la arquitectura de nuestra red neuronal. Lo primero será importar el modelo secuencial que nos permite definir la red neuronal, y `Dense`, que nos permitirá configurar capas densas de nodos dentro de la red:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NXuXJktLuTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX5AN2iTevlo",
        "colab_type": "text"
      },
      "source": [
        "Procedemos a inicializar un clasificador instanciando el modelo secuencial:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2K-DkZZLxfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BNi4x77e1Uu",
        "colab_type": "text"
      },
      "source": [
        "Y ahora vamos añadiendo capas:\n",
        " - Entrada\n",
        " - Capas ocultas\n",
        " - Capa de salida\n",
        "\n",
        "Inicializamos los valores de cada capa con una [distribución aleatoria uniforme](https://keras.io/api/layers/initializers/#randomuniform-class):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGDheyKlL1De",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding the input layer and the first hidden layer\n",
        "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 30))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "classifier.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "\n",
        "# Adding the output layer\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIQ5aglEf65U",
        "colab_type": "text"
      },
      "source": [
        "Compilamos la red neuronal utilizando adam como optimizador y entropía cruzada binaria como función de pérdida:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8bdSoU7M8e_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0EcwfxPgIxu",
        "colab_type": "text"
      },
      "source": [
        "Y por último procedemos al entrenamiento de la red:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ3Z7jPaM_I4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit(X_train, y_train, batch_size = 10, epochs = 80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohIQXWfugQaM",
        "colab_type": "text"
      },
      "source": [
        "Realizamos la predicción sobre los valores de pruebas para poder componer la matriz de confusión:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeFiVvqLNBfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFy6M71ogeWd",
        "colab_type": "text"
      },
      "source": [
        "Podemos ver que tenemos 70 True Negatives, 1 False Positive, 1 False Negative, y 42 True Positives:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_aHVatt1GUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}